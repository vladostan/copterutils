{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.abspath('data')\n",
    "\n",
    "SOURCE_IMAGES = [os.path.join(PATH, \"images/ds1\"),\n",
    "                os.path.join(PATH, \"images/ds2\")]\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for si in SOURCE_IMAGES:\n",
    "    images.extend(glob(os.path.join(si, \"*.jpg\")))\n",
    "    labels.extend(glob(os.path.join(si.replace(\"images\",\"labels\"), \"*.png\")))\n",
    "    \n",
    "print(\"Datasets used: {}\\n\".format(SOURCE_IMAGES))\n",
    "\n",
    "images.sort()\n",
    "labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path):\n",
    "    \n",
    "    image = plt.imread(path)\n",
    "    \n",
    "    return(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "\n",
    "    label = plt.imread(path, 0)\n",
    "    \n",
    "    return(np.asarray(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_image(images[0]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    \n",
    "    # Crop squared image\n",
    "    h, w = x.shape[:2]\n",
    "\n",
    "    x = x[:,(w-h)//2:(w-(w-h)//2),:]\n",
    "    \n",
    "    h, w = x.shape[:2]\n",
    "    \n",
    "    # Split images and masks into batches (optional)\n",
    "    h_t, w_t = (512,512)\n",
    "    split_factor = 4 # We crop this number of smaller images out of one\n",
    "    x_t = np.zeros([split_factor, h_t, w_t, 3], dtype='uint8')\n",
    "    \n",
    "    x_t[0] = x[:h//2,:w//2,:]\n",
    "    x_t[1] = x[:h//2,w//2:w,:]\n",
    "    x_t[2] = x[h//2:h,:w//2,:]\n",
    "    x_t[3] = x[h//2:h,w//2:w,:]\n",
    "    \n",
    "#     x_t = np.float32(x_t/255.)\n",
    "\n",
    "    return(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_output(y):\n",
    "    \n",
    "    # Crop squared image\n",
    "    h, w = y.shape[:2]\n",
    "\n",
    "    y = y[:,(w-h)//2:(w-(w-h)//2)]\n",
    "    \n",
    "    h, w = y.shape[:2]\n",
    "    \n",
    "    # Split images and masks into batches (optional)\n",
    "    h_t, w_t = (512,512)\n",
    "    split_factor = 4 # We crop this number of smaller images out of one\n",
    "    y_t = np.zeros([split_factor, h_t, w_t], dtype='uint8')\n",
    "    \n",
    "    y_t[0] = y[:h//2,:w//2]\n",
    "    y_t[1] = y[:h//2,w//2:w]\n",
    "    y_t[2] = y[h//2:h,:w//2]\n",
    "    y_t[3] = y[h//2:h,w//2:w]\n",
    "    \n",
    "#     y_t = to_categorical(y_t, num_classes=9)\n",
    "#     y_t = y_t.reshape(y_t.shape[:3] + (9,))\n",
    "#     y_t = y_t.astype('int8')\n",
    "\n",
    "    return(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = get_label(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = preprocess_output(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images_train))\n",
    "print(len(labels_train))\n",
    "print(len(images_test))\n",
    "print(len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip,\n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    ShiftScaleRotate,\n",
    "    OneOf,\n",
    "    Compose,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma\n",
    ")\n",
    "\n",
    "def augment_big(image, mask):\n",
    "\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    \n",
    "    aug = Compose([\n",
    "        RandomSizedCrop(p=0.5, min_max_height=(original_height//2, original_height), height=original_height, width=original_width),\n",
    "        OpticalDistortion(p=0.5, distort_limit=0.25, shift_limit=0.5),\n",
    "        OneOf([\n",
    "            CLAHE(p=1., clip_limit=4.),\n",
    "            RandomContrast(p=1., limit=0.25),\n",
    "            RandomGamma(p=1., gamma_limit=(50,200))\n",
    "            ], p=0.5),\n",
    "        ], p=0.5)\n",
    "\n",
    "    augmented = aug(image=image, mask=mask)\n",
    "\n",
    "    image_heavy = augmented['image']\n",
    "    mask_heavy = augmented['mask']\n",
    "    \n",
    "    return image_heavy, mask_heavy\n",
    "\n",
    "def augment_small(image, mask):\n",
    "\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    \n",
    "    aug = Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        ShiftScaleRotate(shift_limit=0.1, scale_limit=0, rotate_limit=20, p=0.5),\n",
    "        ], p=0.5)\n",
    "\n",
    "    augmented = aug(image=image, mask=mask)\n",
    "\n",
    "    image_heavy = augmented['image']\n",
    "    mask_heavy = augmented['mask']\n",
    "    \n",
    "    return image_heavy, mask_heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def train_generator(images_path, labels_path, batch_size = 1):\n",
    "    \n",
    "    while True:\n",
    "        ids = np.random.randint(0, len(images_path), batch_size)\n",
    "        \n",
    "        image_batch = np.take(images_path, ids)\n",
    "        label_batch = np.take(labels_path, ids)\n",
    "        \n",
    "        batch_input = np.zeros([batch_size, 1024, 1280, 3], dtype='uint8')\n",
    "        batch_output = np.zeros([batch_size, 1024, 1280], dtype='uint8') \n",
    "\n",
    "        # READ Images and masks:\n",
    "        for i in range(len(image_batch)):\n",
    "            inp = get_image(image_batch[i])\n",
    "            batch_input[i] = inp\n",
    "            outp = get_label(label_batch[i])\n",
    "            batch_output[i] = outp\n",
    "\n",
    "        # Albumentations augmentation:\n",
    "        for i in range(len(batch_input)):\n",
    "            batch_input[i], batch_output[i]  = augment_big(batch_input[i], batch_output[i])\n",
    "        \n",
    "        # Preprocess Images and masks:\n",
    "        inp = []\n",
    "        outp = []\n",
    "        for i in range(len(batch_input)):\n",
    "            inp.extend(preprocess_input(batch_input[i]))\n",
    "            outp.extend(preprocess_output(batch_output[i]))\n",
    "            \n",
    "        inp = np.asarray(inp)\n",
    "        outp = np.asarray(outp)\n",
    "\n",
    "        # Return a tuple of (input,output) to feed the network\n",
    "        ids = np.random.randint(0, batch_size*4, batch_size)\n",
    "        \n",
    "        batch_x = np.array(inp)\n",
    "        batch_y = np.array(outp)\n",
    "        \n",
    "        batch_x = np.take(batch_x, ids, axis = 0)\n",
    "        batch_y = np.take(batch_y, ids, axis = 0)\n",
    "        \n",
    "        out_x = np.zeros_like(batch_x)\n",
    "        out_y = np.zeros_like(batch_y)\n",
    "        \n",
    "        # AUGMENT\n",
    "        for i in range(len(batch_x)):\n",
    "            image_heavy, mask_heavy  = augment_small(batch_x[i], batch_y[i])\n",
    "            out_x[i] = image_heavy\n",
    "            out_y[i] = mask_heavy\n",
    "            \n",
    "        out_x = np.float32(out_x/255.)\n",
    "        \n",
    "        out_y = to_categorical(out_y, num_classes=9)\n",
    "        out_y = out_y.reshape(out_y.shape[:3] + (9,))\n",
    "        out_y = out_y.astype('int8')\n",
    "            \n",
    "        yield(out_x, out_y)      \n",
    "#         return(out_x, out_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_generator(images_path, labels_path, batch_size = 1):\n",
    "    \n",
    "    while True:\n",
    "        ids = np.random.randint(0, len(images_path), batch_size)\n",
    "        \n",
    "        image_batch = np.take(images_path, ids)\n",
    "        label_batch = np.take(labels_path, ids)\n",
    "        \n",
    "        batch_input = np.zeros([batch_size, 1024, 1280, 3], dtype='uint8')\n",
    "        batch_output = np.zeros([batch_size, 1024, 1280], dtype='uint8') \n",
    "\n",
    "        # READ Images and masks:\n",
    "        for i in range(len(image_batch)):\n",
    "            inp = get_image(image_batch[i])\n",
    "            batch_input[i] = inp\n",
    "            outp = get_label(label_batch[i])\n",
    "            batch_output[i] = outp\n",
    "        \n",
    "        # Preprocess Images and masks:\n",
    "        inp = []\n",
    "        outp = []\n",
    "        for i in range(len(batch_input)):\n",
    "            inp.extend(preprocess_input(batch_input[i]))\n",
    "            outp.extend(preprocess_output(batch_output[i]))\n",
    "            \n",
    "        inp = np.asarray(inp)\n",
    "        outp = np.asarray(outp)\n",
    "\n",
    "        # Return a tuple of (input,output) to feed the network\n",
    "        ids = np.random.randint(0, batch_size*4, batch_size)\n",
    "        \n",
    "        batch_x = np.array(inp)\n",
    "        batch_y = np.array(outp)\n",
    "        \n",
    "        out_x = np.take(batch_x, ids, axis = 0)\n",
    "        out_y = np.take(batch_y, ids, axis = 0)\n",
    "            \n",
    "        out_x = np.float32(out_x/255.)\n",
    "        \n",
    "        out_y = to_categorical(out_y, num_classes=9)\n",
    "        out_y = out_y.reshape(out_y.shape[:3] + (9,))\n",
    "        out_y = out_y.astype('int8')\n",
    "            \n",
    "        yield(out_x, out_y)      \n",
    "#         return(out_x, out_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_generator(images_path=images_train, labels_path=labels_train, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = val_generator(images_path=images_test, labels_path=labels_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_gen[0].shape)\n",
    "print(train_gen[1].shape)\n",
    "print(val_gen[0].shape)\n",
    "print(val_gen[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webcolors\n",
    "\n",
    "def colorize(mask):\n",
    "    hex_colors = ['#000000','#4A4A4A','#FF0000', '#407700', '#00FF37', '#8B572A', '#0000FF', '#FF7600', '#50E3C2']\n",
    "\n",
    "    rgb_colors = []\n",
    "\n",
    "    for hex_color in hex_colors:\n",
    "        rgb_colors.append(webcolors.hex_to_rgb(hex_color))\n",
    "        \n",
    "    colors = np.array(rgb_colors)\n",
    "        \n",
    "    colorMask = np.zeros([mask.shape[0], mask.shape[1], 3],dtype=np.uint8)\n",
    "    for r in range(mask.shape[0]):\n",
    "        for c in range(mask.shape[1]):\n",
    "            colorMask[r,c,] = colors[mask[r,c]]\n",
    "\n",
    "    return colorMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_size_inches(10,5)\n",
    "axes[0].imshow(train_gen[0][img])\n",
    "axes[1].imshow(colorize(train_gen[1][img]))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Unet import unet\n",
    "\n",
    "model = unet(input_size = (512,512,3), n_classes=9)\n",
    "\n",
    "print(\"Model summary:\")\n",
    "model.summary()\n",
    "\n",
    "# In[ ]:\n",
    "from keras import optimizers\n",
    "\n",
    "#model.compile(optimizer = 'adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = optimizers.Adam(lr = learning_rate)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "print(\"Optimizer: {}, learning rate: {}, loss: {}, metrics: {}\\n\".format(optimizer, learning_rate, loss, metrics))\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(images_train)//batch_size*4*2 # 4 crops * twice run\n",
    "validation_steps = len(images_test)//batch_size*4 # 4 crops\n",
    "epochs = 1\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data = val_gen,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_steps = validation_steps,\n",
    "    epochs = epochs,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
